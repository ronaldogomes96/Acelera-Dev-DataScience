{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio 3\n",
    "\n",
    "Neste desafio, iremos praticar nossos conhecimentos sobre distribuições de probabilidade. Para isso,\n",
    "dividiremos este desafio em duas partes:\n",
    "    \n",
    "1. A primeira parte contará com 3 questões sobre um *data set* artificial com dados de uma amostra normal e\n",
    "    uma binomial.\n",
    "2. A segunda parte será sobre a análise da distribuição de uma variável do _data set_ [Pulsar Star](https://archive.ics.uci.edu/ml/datasets/HTRU2), contendo 2 questões.\n",
    "\n",
    "> Obs.: Por favor, não modifique o nome das funções de resposta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Setup_ geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as sct\n",
    "import seaborn as sns\n",
    "from statsmodels.distributions.empirical_distribution import ECDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "\n",
    "figsize(12, 8)\n",
    "\n",
    "sns.set()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Setup_ da parte 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "    \n",
    "dataframe = pd.DataFrame({\"normal\": sct.norm.rvs(20, 4, size=10000),\n",
    "                     \"binomial\": sct.binom.rvs(100, 0.2, size=10000)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicie sua análise a partir da parte 1 a partir daqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sua análise da parte 1 começa aqui.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1\n",
    "\n",
    "Qual a diferença entre os quartis (Q1, Q2 e Q3) das variáveis `normal` e `binomial` de `dataframe`? Responda como uma tupla de três elementos arredondados para três casas decimais.\n",
    "\n",
    "Em outra palavras, sejam `q1_norm`, `q2_norm` e `q3_norm` os quantis da variável `normal` e `q1_binom`, `q2_binom` e `q3_binom` os quantis da variável `binom`, qual a diferença `(q1_norm - q1 binom, q2_norm - q2_binom, q3_norm - q3_binom)`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1():\n",
    "    # Retorne aqui o resultado da questão 1.\n",
    "    q1_norm = np.quantile(dataframe[\"normal\"], .25)\n",
    "    q2_normal = np.quantile(dataframe[\"normal\"], .50)\n",
    "    q3_normal = np.quantile(dataframe[\"normal\"], .75)\n",
    "\n",
    "    q1_binom = np.quantile(dataframe[\"binomial\"], .25)\n",
    "    q2_binom = np.quantile(dataframe[\"binomial\"], .50)\n",
    "    q3_binom = np.quantile(dataframe[\"binomial\"], .75)\n",
    "\n",
    "    q1 = (q1_norm-q1_binom).round(3)\n",
    "    q2 = (q2_normal-q2_binom).round(3)\n",
    "    q3 = (q3_normal-q3_binom).round(3)\n",
    "\n",
    "    return (q1, q2, q3)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para refletir:\n",
    "\n",
    "* Você esperava valores dessa magnitude?\n",
    "\n",
    "* Você é capaz de explicar como distribuições aparentemente tão diferentes (discreta e contínua, por exemplo) conseguem dar esses valores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 2\n",
    "\n",
    "Considere o intervalo $[\\bar{x} - s, \\bar{x} + s]$, onde $\\bar{x}$ é a média amostral e $s$ é o desvio padrão. Qual a probabilidade nesse intervalo, calculada pela função de distribuição acumulada empírica (CDF empírica) da variável `normal`? Responda como uma único escalar arredondado para três casas decimais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2():\n",
    "    # Retorne aqui o resultado da questão 2.\n",
    "    intervaloQuartilicoNormal = [dataframe[\"normal\"].mean() - dataframe[\"normal\"].std(), dataframe[\"normal\"].mean() + dataframe[\"normal\"].std()]\n",
    "    probabilidadeMinima = sct.norm.cdf( intervaloQuartilicoNormal[0], 20, 4)\n",
    "    probabilidadeMaxima = sct.norm.cdf( intervaloQuartilicoNormal[1], 20, 4)\n",
    "    probabilidadeEntre = probabilidadeMaxima - probabilidadeMinima\n",
    "\n",
    "    return  probabilidadeEntre.round(3)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para refletir:\n",
    "\n",
    "* Esse valor se aproxima do esperado teórico?\n",
    "* Experimente também para os intervalos $[\\bar{x} - 2s, \\bar{x} + 2s]$ e $[\\bar{x} - 3s, \\bar{x} + 3s]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 3\n",
    "\n",
    "Qual é a diferença entre as médias e as variâncias das variáveis `binomial` e `normal`? Responda como uma tupla de dois elementos arredondados para três casas decimais.\n",
    "\n",
    "Em outras palavras, sejam `m_binom` e `v_binom` a média e a variância da variável `binomial`, e `m_norm` e `v_norm` a média e a variância da variável `normal`. Quais as diferenças `(m_binom - m_norm, v_binom - v_norm)`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3():\n",
    "    # Retorne aqui o resultado da questão 3.\n",
    "    m_binom = dataframe[\"binomial\"].mean()\n",
    "    v_binom = dataframe[\"binomial\"].var()\n",
    "\n",
    "    m_norm = dataframe[\"normal\"].mean()\n",
    "    v_norm = dataframe[\"normal\"].var()\n",
    "\n",
    "    media = m_binom - m_norm\n",
    "    variancia = v_binom - v_norm\n",
    "    return  (media.round(3), variancia.round(3))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para refletir:\n",
    "\n",
    "* Você esperava valore dessa magnitude?\n",
    "* Qual o efeito de aumentar ou diminuir $n$ (atualmente 100) na distribuição da variável `binomial`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Setup_ da parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File pulsar_stars.csv does not exist: 'pulsar_stars.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-36539e8ba813>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mstars\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"pulsar_stars.csv\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m stars.rename({old_name: new_name\n\u001B[1;32m      4\u001B[0m               \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mold_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnew_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m               in zip(stars.columns,\n",
      "\u001B[0;32m~/Desktop/Acelera-Dev-DataScience/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mparser_f\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001B[0m\n\u001B[1;32m    674\u001B[0m         )\n\u001B[1;32m    675\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 676\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    677\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    678\u001B[0m     \u001B[0mparser_f\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/Acelera-Dev-DataScience/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    446\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    447\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 448\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfp_or_buf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    449\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    450\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/Acelera-Dev-DataScience/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    878\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    879\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 880\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    881\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    882\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/Acelera-Dev-DataScience/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1112\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"c\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1113\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"c\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1114\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mCParserWrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1115\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1116\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"python\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/Acelera-Dev-DataScience/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m   1889\u001B[0m         \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"usecols\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0musecols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1890\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1891\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparsers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTextReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1892\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1893\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.__cinit__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] File pulsar_stars.csv does not exist: 'pulsar_stars.csv'"
     ]
    }
   ],
   "source": [
    "stars = pd.read_csv(\"pulsar_stars.csv\")\n",
    "\n",
    "stars.rename({old_name: new_name\n",
    "              for (old_name, new_name)\n",
    "              in zip(stars.columns,\n",
    "                     [\"mean_profile\", \"sd_profile\", \"kurt_profile\", \"skew_profile\", \"mean_curve\", \"sd_curve\", \"kurt_curve\", \"skew_curve\", \"target\"])\n",
    "             },\n",
    "             axis=1, inplace=True)\n",
    "\n",
    "stars.loc[:, \"target\"] = stars.target.astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicie sua análise da parte 2 a partir daqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sua análise da parte 2 começa aqui.\n",
    "false_pulsar_mean_profile_standardized = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 4\n",
    "\n",
    "Considerando a variável `mean_profile` de `stars`:\n",
    "\n",
    "1. Filtre apenas os valores de `mean_profile` onde `target == 0` (ou seja, onde a estrela não é um pulsar).\n",
    "2. Padronize a variável `mean_profile` filtrada anteriormente para ter média 0 e variância 1.\n",
    "\n",
    "Chamaremos a variável resultante de `false_pulsar_mean_profile_standardized`.\n",
    "\n",
    "Encontre os quantis teóricos para uma distribuição normal de média 0 e variância 1 para 0.80, 0.90 e 0.95 através da função `norm.ppf()` disponível em `scipy.stats`.\n",
    "\n",
    "Quais as probabilidade associadas a esses quantis utilizando a CDF empírica da variável `false_pulsar_mean_profile_standardized`? Responda como uma tupla de três elementos arredondados para três casas decimais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q4():\n",
    "    # Retorne aqui o resultado da questão 4.\n",
    "    #Filtre apenas os valores de mean_profile onde target == 0\n",
    "    mean_profile = []\n",
    "    for i in range(stars.shape[0]):\n",
    "        if stars[\"target\"][i] == False:\n",
    "            mean_profile.append(stars[\"mean_profile\"][i])\n",
    "\n",
    "    #Padronize a variável mean_profile filtrada anteriormente para ter média 0 e variância 1.\n",
    "    media = np.mean(mean_profile)\n",
    "    desvioPadrao = np.std(mean_profile)\n",
    "    for i in range(len(mean_profile)):\n",
    "        false_pulsar_mean_profile_standardized.append((mean_profile[i] - media) / desvioPadrao)\n",
    "\n",
    "    #Encontre os quantis teóricos para uma distribuição normal de média 0 e variância 1 para 0.80, 0.90 e 0.95 através da função `norm.ppf()` disponível em `scipy.stats`.\n",
    "    q80 = sct.norm.ppf(0.80, 0, 1)\n",
    "    q90 = sct.norm.ppf(0.90, 0, 1)\n",
    "    q95 = sct.norm.ppf(0.95, 0, 1)\n",
    "\n",
    "    #Quais as probabilidade associadas a esses quantis utilizando a CDF empírica da variável `false_pulsar_mean_profile_standardized`?\n",
    "    #Responda como uma tupla de três elementos arredondados para três casas decimais.\n",
    "    probabilidadeq80  = sct.norm.cdf(q80, 0, 1)\n",
    "    probabilidadeq90 = sct.norm.cdf(q90, 0, 1)\n",
    "    probabilidadeq95 = sct.norm.cdf(q95, 0, 1)\n",
    "\n",
    "    return  (probabilidadeq80.round(3), probabilidadeq90.round(3), probabilidadeq95.round(3))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para refletir:\n",
    "\n",
    "* Os valores encontrados fazem sentido?\n",
    "* O que isso pode dizer sobre a distribuição da variável `false_pulsar_mean_profile_standardized`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 5\n",
    "\n",
    "Qual a diferença entre os quantis Q1, Q2 e Q3 de `false_pulsar_mean_profile_standardized` e os mesmos quantis teóricos de uma distribuição normal de média 0 e variância 1? Responda como uma tupla de três elementos arredondados para três casas decimais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q5():\n",
    "    # Retorne aqui o resultado da questão 5.\n",
    "    #Quantis teoricos de distribuicao normal\n",
    "    qNormal25 = sct.norm.ppf(0.25, 0, 1)\n",
    "    qNormal50 = sct.norm.ppf(0.50, 0, 1)\n",
    "    qNormal75 = sct.norm.ppf(0.75, 0, 1)\n",
    "\n",
    "    #Quantis da variavel false_pulsar_mean_profile_standardized\n",
    "    qStar25 = np.quantile(false_pulsar_mean_profile_standardized, .25)\n",
    "    qStar50 = np.quantile(false_pulsar_mean_profile_standardized, .50)\n",
    "    qStar75 = np.quantile(false_pulsar_mean_profile_standardized, .75)\n",
    "\n",
    "    #Diferenca\n",
    "    q25 = qStar25 - qNormal25\n",
    "    q50 = qStar50 - qNormal50\n",
    "    q75 = qStar75 - qNormal75\n",
    "\n",
    "    return (q25.round(3), q50.round(3), q75.round(3))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para refletir:\n",
    "\n",
    "* Os valores encontrados fazem sentido?\n",
    "* O que isso pode dizer sobre a distribuição da variável `false_pulsar_mean_profile_standardized`?\n",
    "* Curiosidade: alguns testes de hipóteses sobre normalidade dos dados utilizam essa mesma abordagem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}